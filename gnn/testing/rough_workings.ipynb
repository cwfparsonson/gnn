{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:3', device_type='XLA_GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())\n",
    "import dgl\n",
    "from gnn.models.tools import load_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, features, labels, train_mask, val_mask, test_mask = load_data('cora')\n",
    "\n",
    "print('\\nGraph:\\n{}'.format(g))\n",
    "print('\\nFeatures:\\n{}'.format(features))\n",
    "print('\\nLabels:\\n{}'.format(labels))\n",
    "print('\\nTrain mask:\\n{}'.format(train_mask))\n",
    "print('\\nVal mask:\\n{}'.format(val_mask))\n",
    "print('\\nTest mask:\\n{}'.format(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = g.nodes()\n",
    "print('Node ids:\\n{}'.format(node_ids))\n",
    "\n",
    "train_nids = []\n",
    "index = 0\n",
    "for m in train_mask.numpy():\n",
    "    if m:\n",
    "        train_nids.append(node_ids[index])\n",
    "    else:\n",
    "        pass\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "batch_size = 32\n",
    "num_neighbors = 4\n",
    "num_gcn_layers = 3\n",
    "\n",
    "\n",
    "\n",
    "# g, features, labels, train_mask, val_mask, test_mask = load_data('cora')\n",
    "# legacy_graph = dgl.DGLGraphStale(g, readonly=True)\n",
    "\n",
    "\n",
    "# for nf in dgl.contrib.sampling.NeighborSampler(legacy_graph, \n",
    "#                                                batch_size=batch_size,\n",
    "#                                                expand_factor=num_neighbors,\n",
    "#                                                neighbor_type='in',\n",
    "#                                                shuffle=True,\n",
    "#                                                num_hops=num_gcn_layers,\n",
    "#                                                seed_nodes=train_nids):\n",
    "#     pass\n",
    "\n",
    "batch_size = 20\n",
    "minibatches_of_train_nids = []\n",
    "prev_index = 0\n",
    "index = batch_size\n",
    "for batch_num in range(int(len(train_nids)/batch_size)):\n",
    "    minibatches_of_train_nids.append(train_nids[prev_index:index])\n",
    "    prev_index = copy.deepcopy(index)\n",
    "    index += batch_size\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(num_gcn_layers)\n",
    "collator = dgl.dataloading.NodeCollator(g, train_nids, sampler)\n",
    "for batch_of_nodes in minibatches_of_train_nids:\n",
    "    print('\\n\\nbatch of nodes:\\n{}'.format(batch_of_nodes))\n",
    "    input_nodes, output_nodes, blocks = collator.collate(batch_of_nodes)\n",
    "    print('\\ninput nodes:\\n{}'.format(input_nodes))\n",
    "    print('\\noutput nodes:\\n{}'.format(output_nodes))\n",
    "    print('\\nblocks:\\n{}'.format(blocks))\n",
    "\n",
    "\n",
    "# dataloader = dgl.dataloading.NodeDataLoader(g, \n",
    "#                                             train_nids, \n",
    "#                                             sampler,\n",
    "#                                             batch_size=1024,\n",
    "#                                             shuffle=True,\n",
    "#                                             drop_last=False,\n",
    "#                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blocks[0].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks[0].is_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_unique = np.unique(labels)\n",
    "for lab in init_unique:\n",
    "    print(lab)\n",
    "num_classes = int(len(np.unique(labels)))\n",
    "onehot_labels = tf.one_hot(indices=labels, depth=num_classes)\n",
    "unique = np.unique(onehot_labels, axis=0)\n",
    "for lab in unique:\n",
    "    print(lab)\n",
    "    \n",
    "onehot_dict = {lab: onehot_lab for lab, onehot_lab in zip(init_unique, unique)}\n",
    "print(onehot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labels = tf.cast([onehot_dict[l] for l in labels.numpy()], dtype=tf.int64)\n",
    "print(onehot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = dgl.function.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shuffled_labels = tf.random.shuffle(labels, seed=1)\n",
    "print(shuffled_labels)\n",
    "\n",
    "shuffled_labels = tf.random.shuffle(labels, seed=1)\n",
    "print(shuffled_labels)\n",
    "\n",
    "shuffled_onehot_labels = tf.random.shuffle(onehot_labels, seed=1)\n",
    "print(shuffled_onehot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out_feats': [16, 7], 'activations': ['relu', None]}\n",
      "{\"out_feats\": [16, 7], \"activations\": [\"relu\", null]}\n",
      "{'out_feats': [16, 7], 'activations': ['relu', None]}\n"
     ]
    }
   ],
   "source": [
    "layers_config = {'out_feats': [16, 7],\n",
    "                'activations': ['relu', None]}\n",
    "print(layers_config)\n",
    "json_layers_config = json.dumps(layers_config)\n",
    "print(json_layers_config)\n",
    "new_layers_config = json.loads(json_layers_config)\n",
    "print(new_layers_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
